{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNu/7sQwE3p5caQ8q7+WZkk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhila1619/Excler-/blob/main/DAY32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE0Q2IFLLKGj",
        "outputId": "f9b2b285-a607-4720-b01c-67e10a26e636"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQr-4CPSLP52",
        "outputId": "265ae1a1-2e73-4024-93e8-bc71385b72c6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "# Predefined text (you can replace this with any text you'd like)\n",
        "text = \"\"\"\n",
        "Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.\n",
        "\"\"\"\n",
        "\n",
        "# Function to calculate Term Frequency (TF)\n",
        "def calculate_tf(tokens):\n",
        "    # Create a Counter object to count the frequency of each token\n",
        "    token_counts = Counter(tokens)\n",
        "\n",
        "    # Calculate term frequency (TF) by dividing each token's count by the total number of tokens\n",
        "    total_tokens = len(tokens)\n",
        "    tf = {word: count / total_tokens for word, count in token_counts.items()}\n",
        "\n",
        "    return tf\n",
        "\n",
        "# Function to get the top 5 most frequent tokens\n",
        "def get_top_5_tokens(tf):\n",
        "    # Sort the tokens by TF in descending order and get the top 5\n",
        "    sorted_tf = sorted(tf.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_tf[:5]\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Calculate Term Frequency (TF)\n",
        "tf = calculate_tf(tokens)\n",
        "\n",
        "# Get the top 5 most frequent tokens\n",
        "top_5_tokens = get_top_5_tokens(tf)\n",
        "\n",
        "# Display the top 5 most frequent tokens and their TF\n",
        "print(\"Top 5 most frequent tokens:\")\n",
        "for word, freq in top_5_tokens:\n",
        "    print(f\"{word}: {freq:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNrl5hzeLSLt",
        "outputId": "616c0444-b4de-4ea1-a240-901645228f81"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most frequent tokens:\n",
            ",: 0.0538\n",
            "and: 0.0538\n",
            "is: 0.0430\n",
            ".: 0.0430\n",
            "intelligence: 0.0430\n"
          ]
        }
      ]
    }
  ]
}